{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b2974e-bed7-460c-89b4-daac0f3c93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd37d0c-05fa-4c65-ae1a-4b93188f9a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.7202)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just to ensure everything works as expect, like their tutorial\n",
    "_ = torch.manual_seed(123)\n",
    "fid = FrechetInceptionDistance(feature=64) # which part of the inception network to grab\n",
    "imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.uint8)\n",
    "imgs_dist2 = torch.randint(100, 255, (100, 3, 299, 299), dtype=torch.uint8)\n",
    "fid.update(imgs_dist1, real=True)\n",
    "fid.update(imgs_dist2, real=False)\n",
    "fid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4679334-8886-4030-ac33-6fca560c3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9432aee9-e5ee-49aa-8e27-bb5f5e54c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f07bf2-b9e9-4e83-9ba8-13699fd8beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raayan/Desktop\n"
     ]
    }
   ],
   "source": [
    "print(desktop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ba41fd-158f-4381-9a8e-5904fc046ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_path = os.path.join(desktop_path, 'CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c37a5f0-b216-4aeb-aeca-f8cff0e4462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raayan/Desktop/CIFAR10\n"
     ]
    }
   ],
   "source": [
    "print(cifar10_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9782b1e6-d1aa-44f0-9cf5-909c7bbab7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "cifar10 = datasets.CIFAR10(root=cifar10_path, train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b8f77b-b9ed-46e8-adb0-9f78de058aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.6892)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid = FrechetInceptionDistance(feature=64,normalize=True)\n",
    "fid.set_dtype(torch.float32)\n",
    "imgs_dist1 = torch.randint(0, 200, (100, 3, 299, 299), dtype=torch.float32)\n",
    "imgs_dist2 = torch.randint(100, 255, (100, 3, 299, 299), dtype=torch.float32)\n",
    "fid.update(imgs_dist1, real=True)\n",
    "fid.update(imgs_dist2, real=False)\n",
    "fid.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb5e3ee-d80b-4773-bd9c-38ee32aedf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch 1: torch.Size([1000, 3, 32, 32])\n",
      "Shape of batch 2: torch.Size([1000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "data_loader = torch.utils.data.DataLoader(cifar10, batch_size=batch_size, shuffle=True)\n",
    "batch1, _ = next(iter(data_loader))\n",
    "batch2, _ = next(iter(data_loader))\n",
    "\n",
    "print(\"Shape of batch 1:\", batch1.shape)\n",
    "print(\"Shape of batch 2:\", batch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1335c4-0561-4aa6-93a0-23cd38d4a571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9862)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid.update(batch1, real=True)\n",
    "fid.update(batch2, real=False)\n",
    "fid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0586fb-99ea-4b7c-8631-6ef7b917a506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
